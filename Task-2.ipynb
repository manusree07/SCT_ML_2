# Imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
from google.colab import files

# Upload file manually
uploaded = files.upload()


# 1. Load dataset
# (You’ll need to download the CSV from Kaggle and place in your working folder)
data = pd.read_csv("Mall_Customers.csv")

# 2. Quick exploration
print("Shape:", data.shape)
print(data.head())
print(data.info())
print(data.describe())

# 3. Data cleaning / checking for missing values
print("Null counts:\n", data.isnull().sum())


print(data.columns)
print(data.columns.tolist())


# 4. Select features for clustering
# Common choice: “Annual Income (k$)” and “Spending Score (1–100)”
X = data[['Annual Income (k$)', 'Spending Score (1-100)']].copy()

# 5. Scale the features (important for KMeans)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
# 6. Determine optimal number of clusters

# 6a. Elbow method (inertia)
inertia = []
K = range(1, 11)
for k in K:
    km = KMeans(n_clusters=k, random_state=42, n_init=10)
    km.fit(X_scaled)
    inertia.append(km.inertia_)


plt.figure(figsize=(8,5))
plt.plot(K, inertia, 'bo-')
plt.xlabel('Number of clusters k')
plt.ylabel('Inertia (sum of squared distances)')
plt.title('Elbow Method For Optimal k')
plt.show()


# 6b. Silhouette score (for k >= 2)
sil_scores = []
for k in range(2, 11):
    km = KMeans(n_clusters=k, random_state=42, n_init=10)
    labels = km.fit_predict(X_scaled)
    sil = silhouette_score(X_scaled, labels)
    sil_scores.append(sil)
    plt.figure(figsize=(8,5))
plt.plot(range(2, 11), sil_scores, 'ro-')
plt.xlabel('Number of clusters k')
plt.ylabel('Silhouette Score')
plt.title('Silhouette Score vs k')
plt.show()

print("Silhouette scores:", dict(zip(range(2,11), sil_scores)))

# Choose the “best” k (often at elbow or highest silhouette). Suppose k = 5.

best_k = 5
kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)
cluster_labels = kmeans.fit_predict(X_scaled)

# 7. Assign cluster labels to original data
data['Cluster'] = cluster_labels

# 8. Inverse transform cluster centers (to original scale) for interpretation
centers_scaled = kmeans.cluster_centers_
centers = scaler.inverse_transform(centers_scaled)
centers_df = pd.DataFrame(centers, columns=X.columns)
print("Cluster centers (original scale):")
print(centers_df)

# 9. Visualize clusters
plt.figure(figsize=(8,6))
sns.scatterplot(
    x=data['Annual Income (k$)'],
    y=data['Spending Score (1-100)'],
    hue=data['Cluster'],
    palette='Set1',
    s=100,
    alpha=0.75
)

# Plot cluster centers
plt.scatter(centers_df['Annual Income (k$)'], centers_df['Spending Score (1-100)'],
            c='black', s=200, marker='X', label='Centers')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.title(f'Customer Segments (k={best_k})')
plt.legend(title='Cluster')
plt.show()
# 10. Profile each cluster (insights)
cluster_profile = data.groupby('Cluster').agg({
    'Age': 'mean',
    'Annual Income (k$)': 'mean',
    'Spending Score (1-100)': 'mean',
    'CustomerID': 'count'
}).rename(columns={'CustomerID': 'Count'})
print("\nCluster Profile Summary:")
print(cluster_profile.sort_index())


